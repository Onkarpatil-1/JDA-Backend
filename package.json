{
    "name": "ollama-sla-backend",
    "version": "1.0.0",
    "description": "Backend API wrapper for Ollama LLM with SLA anomaly detection and prediction capabilities",
    "type": "module",
    "main": "dist/index.js",
    "scripts": {
        "dev": "tsx watch src/index.ts",
        "build": "tsc",
        "start": "node dist/index.js",
        "test": "node --test"
    },
    "keywords": [
        "ollama",
        "llm",
        "anomaly-detection",
        "sla",
        "ai"
    ],
    "author": "",
    "license": "MIT",
    "dependencies": {
        "@anthropic-ai/sdk": "^0.74.0",
        "@google/generative-ai": "^0.24.1",
        "@types/multer": "^2.0.0",
        "@types/papaparse": "^5.5.2",
        "cors": "^2.8.5",
        "dotenv": "^16.3.1",
        "express": "^4.18.2",
        "multer": "^2.0.2",
        "ollama": "^0.5.0",
        "openai": "^6.21.0",
        "papaparse": "^5.5.3"
    },
    "devDependencies": {
        "@types/cors": "^2.8.17",
        "@types/express": "^4.17.21",
        "@types/node": "^20.10.0",
        "tsx": "^4.7.0",
        "typescript": "^5.3.3"
    }
}
